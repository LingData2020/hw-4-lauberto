---
title: "HW-04"
author: "andrea grillandi"
date: "27/2/2020"
output:
  html_document: 
    theme: lumen
  pdf_document: default
  highlight: tango
---

Linguistic data: Quantitative analysis and vizualization

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Universal linguistic hierarchies: a case of Modern Greek (Standard and Cypriot dialects)
Data ([responces](https://raw.githubusercontent.com/LingData2019/LingData2020/master/data/greek-word-order-mono-acceptability-coded-rt.txt), [quesionnaire](https://raw.githubusercontent.com/LingData2019/LingData2020/master/data/greek-word-order-mono_socio.txt)) adapted from the survey:
Leivada, Evelina; Westergaard, Marit, 2019, [Universal linguistic hierarchies are not innately wired](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6679903/#fn-1). PeerJ, v.7.

Source of data: TROLLing repository:
Leivada, Evelina; Westergaard, Marit, 2019, "Replication Data for: Universal linguistic hierarchies are not innately wired", https://doi.org/10.18710/NTLLUF, DataverseNO, V1


#### Constructions with two adjectives 

In English, the order of two adjectives in phrases like:
```
 a big black bag # ok
*a black big bag # unacceptable, ungrammatically ill-formed, or semantically anomalous
```
is powered by the semantic class of adjective (e.g. the `color` adjective closer to the noun than the `size` adjective).

A syntactic hierarchy of closeness to the noun in Chomsky's Universal Grammar 
suggests the following order and is claimed to be innate and universal (= valid for all languages).
```
Subjective Comment > Evidential > Size > Length
> Height > Speed > Depth > Width > Temperature > Wetness > Age
> Shape > Color > Nationality/Origin > Material 
# (adapted from Scott, 2002: 114)
```

The goal of Leivada & Westergaard research is identify what happens when people process orderings that either comply with the hierrarchy or violate it.

#### Method

In the first experiment, 140 neurotypical, adult speakers completed a timed forced choice task that featured stimuli showing a combination of two adjectives and a concrete noun (e.g., *I bought a square black table*). Two types of responses were collected: 

(i) acceptability judgments on a 3-point Likert scale that featured the options 
    1. wrong,  
    2. neither correct nor wrong,   
    3. correct;  

(ii) reaction times (RT). 

The task featured three conditions: 1. size adjective > nationality adjective, 2. color adjective > shape adjective, 3. subjective comment adjective > material adjective. Each condition had two orders. In the congruent order, the adjective pair was ordered in agreement with what is traditionally accepted as dictated by the universal hierarchy. In the incongruent order, the ordering was reversed, thus the hierarchy was violated.

In the second experiment, 30 bidialectals (native speakers of Standard and Cypriot Greek) were tested in both language varieties, 36 observations per participant, 18 for each variety.

Two kinds of [fillers](https://www.hlp.rochester.edu/resources/BCS152-Tutorial/Fillers.html) were used in both experiments, FillerAcceptable and FillerUnacceptable -- sentences that included well-formed and ungrammatical structures, respectively. In both tasks the ratio of fillers to actual test structures was 2:1.

#### Data 
```{r}
library(tidyverse)

mono_socio <- read_csv2("https://raw.githubusercontent.com/LingData2019/LingData2020/master/data/greek-word-order-mono_socio.txt")
mono <- read_csv2("https://raw.githubusercontent.com/LingData2019/LingData2020/master/data/greek-word-order-mono-acceptability-coded-rt.txt")
```

see also [reading key for the data](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6679903/bin/peerj-07-7438-s001.txt)

```{r}
colnames(mono_socio)[c(1, 2, 3, 4)] <- c('ID', 'TypeQ', 'Qcat', 'resp')
colnames(mono_socio)
```
## 1. Data overview 
### 1.1

Use `mono_socio` dataframe to answer the following questions:


The following functions from tidyverse can be usefult for this problem: `filter`, `group_by`, `count` and `distinct`. (Another approach is to use `pivot_wider`.)

1. How many participants are mentioned in this dataframe?
1. There are 30 participants, as mono_socio_cleaned df shows.
Answer 1.
```{r}
mono_socio_cleaned <- subset(mono_socio, select = -c(ID, TypeQ))
mono_socio_cleaned %>%
  pivot_wider(names_from = Qcat, values_from = resp, values_fn = list(resp = list)) -> df
age <- unlist(df[, 1], use.names=FALSE)
country1 <- unlist(df[, 2], use.names=FALSE)
country2 <- unlist(df[, 3], use.names=FALSE)
education <- unlist(df[, 4], use.names=FALSE)
handedness <- unlist(df[, 5], use.names=FALSE)
sex <- unlist(df[, 6], use.names=FALSE)

mono_socio_cleaned <- data.frame(age, country1, country2, education, handedness, sex)
```


2. How many of them are males and females?
2. male - 11, female - 19, as shown below.
Answer 2 - male
```{r}
count(filter(mono_socio_cleaned, sex == "male"))
```
Answer 2 - female 
```{r}
count(filter(mono_socio_cleaned, sex == "female"))
```


3. Which education levels are mentioned in the dataframe?
```{r}
education <- select(mono_socio_cleaned, select = 'education')
education <- distinct(education)
education
```

4. How many participants of each education levels are present?
college - 3, uni_degree - 12, postgrad - 14, PhD - 1.
```{r}
count(mono_socio_cleaned, education == 'College')
count(mono_socio_cleaned, education == 'UniversityDegree')
count(mono_socio_cleaned, education == 'Postgraduate')
count(mono_socio_cleaned, education == 'PhDongoing')
```

5. How many left- and right-randed participants are present?
right - 28, left -2

```{r}
count(mono_socio_cleaned, handedness == "right")
count(mono_socio_cleaned, handedness == "left")
```

Compare your overview with that reported in Table 1 of the article. Sometimes replication data provided by authors does not allow on to reproduce their results. Let's look at another dataframe, `mono`, that contains results of experiment 1. 

```{r}
mono
colnames(mono)[c(1, 2, 3, 4, 5, 6)] <- c('ID', 'TypeQ', 'TypeS', 'WO', 'RAJ', 'RT')
colnames(mono)
```


### 1.2
Create a plot that shows the RT distribution in experiment 1 (all participants and conditions taken together). What kind of plot would you choose? Use ggplot() for this problem.

```{r}
library(ggplot2)
mono %>% 
  ggplot(aes(RT))+
  geom_density(alpha = 0.1, color = "blue", fill= "darkblue", size = 0.3)+
  geom_rug()+
  labs(title = "RT distribution",
       x = "Reaction Time (ms)")

```

Can we say that RT approximately follows normal distribution? Which features of RT distribution contradicts this assumption? (E.g. long left tail, long right tail, outliers, skewness, etc.) 

Yes, we can state that RT approximately follows normal distribution. There are of course some outliers, as shown in the boxplot below; plus, we can observe that the graphic lightly stretches out in a tail to the right, but, generally speaking, distribution is normal.

```{r}
boxplot(mono$RT,
main = "RT boxplot",
ylab = "RT (ms)",
col = "orange",
border = "brown",
notch = TRUE
)
```

### 1.3
Normalise data applying the logarithm with base 10 (RTlog = log10(RT)). Use `mutate`.

```{r}
mono <- mutate(mono, RTlog = log10(RT))

```

### 1.4
Create a density plot that shows the RTlog distribution. 

```{r}
mono %>% 
  ggplot(aes(RTlog))+
  geom_density(alpha = 0.4, color = "blue", fill= "darkblue", size = 0.6)+
  geom_rug()+
  labs(title = "RT distribution",
       x = "Reaction Time (ms)")

```

Can we say that RTlog approximately follows normal distribution? What features of RTlog distribution contradicts this assumption? (E.g. long left tail, long right tail, outliers, skewness, etc.) 

### 1.5
Give a summary of `RTlog` distribution (min, max, mean, median, standard deviation)

```{r}
min(mono$RTlog)
max(mono$RTlog)
mean(mono$RTlog)
median(mono$RTlog)
sd(mono$RTlog)
```

### 1.6
Filter out outliers. Remove from the table the following observations:
* responses whose RT is below 600 ms (i.e., when a button is pressed too fast, without allowing enough time for actual consideration of the presented stimuli)  
* responses whose RTlog deviates from the mean value of RTlog for more than 3 standard deviations  
* fillers (both acceptable and unacceptable)  
Convert relevant variables to factors and save fitered data as `mono1`.

```{r}
RTlog_mean <- mean(mono$RTlog)
RTlog_sd <- sd(mono$RTlog)
mono <- mutate(mono, RTlog_diff = abs(RTlog - RTlog_mean))

mono1 <- filter(mono, (TypeS != 'FillerAcceptable' & TypeS !='FillerUnacceptable'))
mono1 <- filter(mono1, RT > 600)
mono1 <- filter(mono1, RTlog_diff < 3*RTlog_sd) 

mono1 %>%  
  select(ID, TypeS, WO, RAJ, RTlog) %>% 
    mutate(ID = as.factor(ID),
    TypeS = as.factor(TypeS), 
         WO = as.factor(WO), 
         RAJ = as.factor(RAJ)) -> mono1
```
### 1.7 
Calculate the number of observations in `mono1`.
```{r}
count(mono1)
```

### 1.8
Reproduce Figure 1 from the article using `ggplot`. 
 
Hint: You can make a summary and use `geom_col()` (see example [here](https://r-graphics.org/recipe-colors-mapping)).
Use either facet_wrap or facet_grid to make six plots.
Note that we figures created in 1.8-1.0 may look different from what plotted in the article.

```{r}
p <- ggplot(mono1, aes(x=TypeS, fill=RAJ)) + 
  geom_histogram(stat="count", position="dodge2", colour="grey40", size=0.4, alpha=0.6)

p +
  facet_grid(cols = vars(WO), scales="free")+
  theme(
      strip.text.x = element_text(
        size = 10, face = "bold"
        ),
      strip.text.y = element_text(
        size = 10, face = "bold"
        )
      )
```

### 1.9
Reproduce Figure 2 from the article using ggplot.

```{r}
p2 <- ggplot(mono1, aes(x=WO, fill=RAJ)) + 
  geom_histogram(stat="count", position="dodge2", colour="grey40", size=0.4, alpha=0.6)

p2 +
  facet_grid(cols = vars(WO), scales="free")+
  theme(
      strip.text.x = element_text(
        size = 10, face = "bold"
        ),
      strip.text.y = element_text(
        size = 10, face = "bold"
        )
      )
```

### 1.10
Reproduce Figure 7 from the article using ggplot.

```{r}
p3 <- ggplot(mono1, aes(x=RAJ, y=RTlog, fill=WO))

dodge <- position_dodge(width=1) 
p3 + geom_violin(size=0.6, color="grey30", position=dodge) +
  geom_boxplot(width=0.4, size=0.6, color="grey10", position=dodge, color="grey") +
  facet_grid(cols = vars(RAJ), scales="free", space="free") +
  theme(
      strip.text.x = element_text(
        size = 10, face = "bold"
        ),
      strip.text.y = element_text(
        size = 10, face = "bold"
        )
      )

```

### 1.11
For the same data, draw a lineplot for group means and standard errors using `ggline()`:

```{r}
ggline(mono1, x = 'RAJ', y = 'RTlog', add = 'mean_se')
```

## 2. Difference in reaction time

Let us test are there any difference in the reaction time between congruent and incongruent orders. Reaction time is a numeric variable so we can use t-test to compare means. One option is to use two-sample t-test. However, as we have data for congruent and incongruent orders for *the same participants*, it is better to use *paired t-test* here. In paired t-test, for each participant, we will find difference of their reaction time in congruent and incongruent orders, and compare these differences with 0 using 1-sample t-test. To make sure that our data satisfy assumptions of t-test (values that we compare are independent samples from some approximately normal distributions), we will find mean logarithm of reaction time for each participant (across ovservations in all conditions), and consider them as our new sample.

### 2.1 Summarising
Use `group_by` and `summarise` to find mean logarithm of reaction time for each participant and each word order. Put this dataframe to `mean_rtlog_long` variable. It should be like

```
# A tibble: 280 x 3
   ParticipantID                    WordOrder   RTlog
   <fct>                            <fct>       <dbl>
 1 00e0b159cf5b9abcc73b92506d8b1c38 Congruent    3.24
 2 00e0b159cf5b9abcc73b92506d8b1c38 Incongruent  3.47
 3 021a49cde484f8fa18439f026ec99459 Congruent    3.22
 4 021a49cde484f8fa18439f026ec99459 Incongruent  3.21
 ...
```

```{r}
mono1 %>%
  group_by(ID, WO) %>%
  summarise(avg = mean(RTlog)) %>%
  arrange(ID) -> mean_rtlog_long
```


### 2.2. Pivoting
Use `pivot_wider` to spread values of `RTlog` in `mean_rtlog_long` into two columns: `Congruent` and `Incongruent`. Put new dataframe in variable `mean_rtlog`. It should look like

```
# A tibble: 140 x 3
   ParticipantID                    Congruent Incongruent
   <fct>                                <dbl>       <dbl>
 1 00e0b159cf5b9abcc73b92506d8b1c38      3.24        3.47
 2 021a49cde484f8fa18439f026ec99459      3.22        3.21
 3 02810ff2a65eae2b3e54ac57d906309d      3.46        3.36
 ```
```{r}
mean_rtlog_long %>%
  pivot_wider(names_from = WO, values_from = avg) -> mean_rtlog

```

### 2.3. Two-sample t-test
Let us try to apply two-sample t-test to our data. Consider values in columns `Congruent` and `Incongruent` as two independent samples. Our null hypothesis is that these two samples are from populations with equal means. Alternative hypothesis: population mean for incongruate word order is larger (people need more time to ’parse’ it). Use `t.test` function to perform a test. Don't forget to specify `alternative`.

```{r}

t.test(mean_rtlog$Congruent, mean_rtlog$Incongruent,
       alternative = "less")
```
Would you reject null hypothesis (under 5% significance level) according to this test?

 - No, I would not reject null hypothesis, because p-value is higher than 0.05.

What claim about logarithms of reaction time for Congruent and Incongruent stimuli can you make according to this test?

 - We can claim that reaction time and type of stimuli (congruent or incongruent) are not directly related.

### 2.4. Paired t-test: manually
To use paired t-test, let us find difference between logarithms of reaction time for each participant. Use `mutate` and add variable `diff` with aforementioned meaning to dataframe `mean_rtlog`. Save result as `mean_rtlog` again. Then compare mean of `diff` with 0 using 1-sample t-test. (Use appropriate alternative.)

```{r}
mean_rtlog <- mutate(mean_rtlog, diff = abs(Congruent - Incongruent))
t.test(mean_rtlog$diff, mu=0, alternative = "greater")

```

Whould you reject null hypothesis?

- Yes, I would, because p-value is lower than 0.05.

What claim about logarithms of reaction time for Congruent and Incongruent stimuli can you make now?

 - We can claim that there is a difference in the reaction time between Congruent and Incongruent stimuli, which is, they are not equal, hence diff != 0. 

How can you interpret difference with the result of 2.3?
- Not sure.  

#### 2.5. Paired t-test out of the box
In fact, we can avoid manual calculation of difference and perform paired t-test using `t.test` function with parameter `paired = True`. Apply this function to your data and make sure you get the same result as in 2.4.

- Like in 2.4, we get to reject null hypothesis, but the p-balue is slightly different.

```{r}
t.test(mean_rtlog$Congruent, mean_rtlog$Incongruent,
       alternative = "less",
       paired = TRUE)
```

## 3. Difference between conditions
Now we will consider reaction time for Incongruent word ordering only. Let us check are there any statistically significant difference in logarithm of reaction time for different conditions (types of stimuli).

### 3.1 Data preparation 
Filter only observation with `Incongruent` word order, then find average logarithm of reaction time for each participant and each type of stimuli. Save new dataframe as `incong_rtlog` variable. It should look like the following table:

```
# A tibble: 420 x 3
   ParticipantID                    TypeOfStimuli              RTlog
   <fct>                            <fct>                      <dbl>
 1 00e0b159cf5b9abcc73b92506d8b1c38 Shape-Color                 3.34
 2 00e0b159cf5b9abcc73b92506d8b1c38 Size-Nationality            3.20
 3 00e0b159cf5b9abcc73b92506d8b1c38 SubjectiveComment-Material  3.19
 4 021a49cde484f8fa18439f026ec99459 Shape-Color                 3.20
```

```{r}
mono1 %>%
  group_by(ID, TypeS) %>%
  summarise(avg = mean(RTlog)) %>%
  arrange(ID) -> incong_rtlog

incong_rtlog %>%
  ungroup(ID, TypeS) %>%
  select(ID, TypeS, avg) %>% 
    mutate(ID = as.factor(ID),
           TypeS = as.factor(TypeS)) -> incong_rtlog

#mono1 %>%
 # group_by(TypeS) %>%
 # shapiro_test(RTlog)
#incong_rtlog %>%
 # pivot_wider(names_from = TypeS, values_from = avg) -> incong_rtlog

```

### 3.2 Statistical testing
Use appropriate statistical test to answer the following question: are there any statistically significant difference in logarithm of reaction time for different conditions (types of stimuli)? Choose the test and provide justification for your choice. Provide your code, results and interpretation. What is your answer to the question?

- I chose to use ANOVA test, because it allows to test difference over 2 or more groups means. Here, the groups we want to test are those from Type of Sequence (Shape-Color, Size-Nationality, SubjectiveComment-Material). I decided to avoid pair-wise t-test, because, as reported during class, it is not performatively reliable on large sets of data, because the probability to reject null hypothesis increases exponentially with the amount of data.

According to ANOVA test I carried out, p-value is above 0.05, hencenull hypothesis cannot be rejected, which means there's no statistically significant difference in logRT for different type of stimuli.

```{r}
res.aov <- aov(avg ~ TypeS, data = incong_rtlog) 
summary(res.aov)
```

### 3.3 Post-hoc analysis: which differences are significant?
If we compare means for several (more than two) groups and reject null hypothesis that corresponding population means are equal to each other, the next natural question is to find all pairs of groups which difference is statistically significant. As we discussed at the lecture, pairwise t-tests cannot be used here without appropriate corrections. Instead, one can use Tukey Honest Significant Differences. It reports adjusted confidence intervals for differences between group means for each pair of groups as well as p-values for null hypothesis ’difference is equal to zero’.

Apply `TukeyHSD` to the result of 3.2 and report which pair of conditions has statistically significant difference between logarithms of reaction time.

```{r}
TukeyHSD(res.aov)
```
